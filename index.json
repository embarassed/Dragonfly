[
{
	"uri": "https://d7y.io/onboarding/",
	"title": "Before Starting",
	"tags": [],
	"description": "",
	"content": " Before getting started, let\u0026rsquo;s take a quick look at how to use this documentation portal of Dragonfly.\nNavigating With a rich set of navigation features, you can always locate your target resource at ease.\nNavigating to the Homepage To go to the homepage of the Dragonfly documentation portal, do one of the following:\n In the breadcrumb of any page, click Dragonfly. In the address bar of the browser, type https://alibaba.github.io/Dragonfly/ and press Enter.  Navigating to a Topic To navigate to a topic, do one of the following:\n In the left-side navigation pane, click a chapter title to expand this chapter, and then click a child topic. In the left-side navigation pane, click a chapter title, and then on the right-side reading pane, click the child topic link.  Navigating to a Specific Section of a Topic Some topics can be lengthy. To jump to a specific section, do the following:\n Hover-over the mini TOC icon in the breadcrumb.\n In the mini TOC overlay, click a section heading.\n  Navigating to Other Related Resources To navigate to other related resources, such as the Dragonfly roadmap, github repo, contributing guide, and so on, click the link under More in the left-side navigation pane.\nSearching Given that the Dragonfly documentation portal is a static website, you can find target information in a blink of an eye.\nTo perform a search, type your key words in the search box on the top of the left-side navigation pane, and matching results will appear in the overlay.\nIn the search results, click any link to jump to the topic, and your key words will be highlighted in yellow.\nImproving the Documentation If you see a typo, or just feel like adding your insights, don\u0026rsquo;t hesitate to click the Edit this page link in the breadcrumb. Then you\u0026rsquo;ll be prompted to sign in your Github account and fork the repository.\n"
},
{
	"uri": "https://d7y.io/user_guide/install_server/",
	"title": "Installing Server",
	"tags": [],
	"description": "",
	"content": "This topic explains how to install the Dragonfly server. Tip: For a data center or a cluster, we recommend that you use at least two machines with eight cores, 16GB RAM and Gigabit Ethernet connections for deploying supernodes.\nContext There are two layers in Dragonfly’s architecture: server (supernodes) and client (hosts). Install the supernodes in one of the following ways:\n Deploying with Docker: Recommended for quick local deployment and test. Deploying with physical machines: Recommended for production usage.  Prerequisites When deploying with Docker, the following conditions must be met.\n   Required Software Version Limit     Git 1.9.1+   Docker 1.12.0+    When deploying with physical machines, the following conditions must be met.\n   Required Software Version Limit     Git 1.9.1+   JDK 1.7+   Maven 3.0.3+   Nginx 0.8+    Procedure - When Deploying with Docker  Obtain the source code of Dragonfly.\ngit clone https://github.com/alibaba/Dragonfly.git  Enter the project directory.\ncd Dragonfly  Build the Docker image.\n./build/build.sh supernode  Obtain the latest Docker image ID of the supernode.\ndocker image ls|grep 'supernode' |awk '{print $3}' | head -n1  Start the supernode.\n# Replace ${supernodeDockerImageId} with the ID obtained at the previous step docker run -d -p 8001:8001 -p 8002:8002 ${supernodeDockerImageId}   Procedure - When Deploying with Physical Machines  Obtain the source code of Dragonfly.\ngit clone https://github.com/alibaba/Dragonfly.git  Enter the project directory.\ncd Dragonfly/src/supernode  Compile the source code.\nmvn clean -U install -DskipTests=true  Start the supernode.\n# If the 'supernode.baseHome’ is not specified, then the default value '/home/admin/supernode’ will be used. java -Dsupernode.baseHome=/home/admin/supernode -jar target/supernode.jar  Add the following configuration items to the Nginx configuration file.\nTip: The path of the Nginx configuration file is something like src/supernode/src/main/docker/sources/nginx.conf.\nserver { listen 8001; location / { # Must be ${supernode.baseHome}/repo root /home/admin/supernode/repo; } } server { listen 8002; location /peer { proxy_pass http://127.0.0.1:8080; } }  Start Nginx.\nsudo nginx   After this Task  After the supernode is installed, run the following commands to verify if Nginx and Tomcat are started, and if Port 8001 and 8002 are available.\nps aux|grep nginx ps aux|grep tomcat telnet 127.0.0.1 8001 telent 127.0.0.1 8002  Install the Dragonfly client and test if the downloading works.\ndfget --url \u0026quot;http://${resourceUrl}\u0026quot; --output ./resource.png --node \u0026quot;127.0.0.1\u0026quot;  "
},
{
	"uri": "https://d7y.io/overview/what_is_dragonfly/",
	"title": "What Is Dragonfly?",
	"tags": [],
	"description": "",
	"content": "Dragonfly is an intelligent P2P-based image and file distribution tool. It aims to improve the efficiency and success rate of file transferring, and maximize the usage of network bandwidth, especially for the distribution of larget amounts of data, such as application distribution, cache distribution, log distribution, and image distribution. At Alibaba, every month Dragonfly is invoked two billion times and distributes 3.4PB of data. Dragonfly has become one of the most important pieces of infrastructure at Alibaba.\nWhile container technologies makes DevOps life easier most of the time, it surely brings some challenges: for example the efficiency of image distribution, especially when you have to replicate image distribution on several hosts.\nDragonfly works extremely well with both Docker and PouchContainer in this scenario. It\u0026rsquo;s also compatible with containers of other formats. It delivers up to 57 times the throughput of native docker and saves up to 99.5% of the out bandwidth of registry.\nDragonfly makes it simple and cost-effective to set up, operate, and scale any kind of file, image, or data distribution.\nWhy Dragonfly This project is an open-source version of the Dragonfly used at Alibaba. It has the following features:\nNote: More Alibaba-internal features will be made available to open-source users soon. Stay tuned!\n P2P-based file distribution: By using the P2P technology for file transmission, it makes the most out of the bandwidth resources of each peer to improve downloading efficiency, and saves a lot of cross-IDC bandwidth, especially the costly cross-board bandwidth. Non-invasive support to all kinds of container technologies: Dragonfly can seamlessly support various containers for distributing images. Host level speed limit: In addition to rate limit for the current download task like many other downloading tools (for example wget and curl), Dragonfly also provides rate limit for the entire host. Passive CDN: The CDN mechanism can avoid repetitive remote downloads. Strong consistency: Dragonfly can make sure that all downloaded files are consistent even if users do not provide any check code (MD5). Disk protection and highly efficient IO: Prechecking disk space, delaying synchronization, writing file blocks in the best order, isolating net-read/disk-write, and so on. High performance: Cluster Manager is completely closed-loop, which means that it doesn\u0026rsquo;t rely on any database or distributed cache, processing requests with extremely high performance. Auto-isolation of Exception: Dragonfly will automatically isolate exception nodes (peer or Cluster Manager) to improve download stability. No pressure on file source: Generally, only a few Cluster Managers will download files from the source. Support standard HTTP header: Support submitting authentication information through HTTP header. Effective concurrency control of Registry Auth: Reduce the pressure on the Registry Auth Service. Simple and easy to use: Very few configurations are needed.  How Does It Stack Up Against Traditional Solution? We carried out an experiment to compare the performance of Dragonfly and wget.\n   Test Environment      Dragonfly Server 2 * (24-Core 64GB-RAM 2000Mb/s)   File Source Server 2 * (24-Core 64GB-RAM 2000Mb/s)   Client 4-Core 8GB-RAM 200Mb/s   Target File Size 200MB   Experiment Date April 20, 2016    The expeirment result is as shown in the following figure.\nAs you can see in the chart, for Dragonfly, no matter how many clients are downloading, the average downloading time is always about 12 seconds. But for wget, the downloading time keeps increasing with the number of clients. When the number of wget clients reaches 1,200, the file source crashed and therefore cannot serve any client.\nHow Does It Work? Dragonfly works slightly differently when downloading general files and downloading container images.\nDownloading General Files The Cluster Manager is also called a supernode, which is responsible for CDN and scheduling every peer to transfer blocks between each other. dfget is the P2P client, which is also called \u0026ldquo;peer\u0026rdquo;. It\u0026rsquo;s mainly used to download and share blocks.\nDownloading Container Images Registry is similar to the file server above. dfget proxy is also called dfdaemon, which intercepts HTTP requests from docker pull or docker push, and then decides which requests to process with dfget.\nDownloading Blocks Every file is divided into multiple blocks, which are transmitted between peers. Each peer is a P2P client. Cluster Manager will check if the corresponding file exists in the local disk. If not, it will be downloaded into Cluster Manager from file server.\n"
},
{
	"uri": "https://d7y.io/cli_reference/dfdaemon/",
	"title": "dfdaemon",
	"tags": [],
	"description": "",
	"content": "dfdaemon is a proxy between pouchd/dockerd and registry used for pulling images. You can use the dfdaemon command in the command line tool. Name dfdaemon - a proxy between pouchd/dockerd and registry used for pulling images.\nSynopsis dfdaemon [options]...\nOptions -callsystem string caller name (default \u0026quot;com_ops_dragonfly\u0026quot;) -certpem string cert.pem file path -dfpath string dfget path (default is your installed path) -h help -hostIp string dfdaemon host ip, default: 127.0.0.1 (default \u0026quot;127.0.0.1\u0026quot;) -keypem string key.pem file path -localrepo string temp output dir of dfdaemon (default is \u0026quot;${HOME}/.small-dragonfly/dfdaemon/data\u0026quot;) -maxprocs int the maximum number of CPUs that the dfdaemon can use (default 4) -notbs not try back source to download if throw exception (default true) -port uint dfdaemon will listen the port (default 65001) -ratelimit string net speed limit,format:xxxM/K -registry string registry addr(https://abc.xx.x or http://abc.xx.x) and must exist if dfdaemon is used to mirror mode -rule string download the url by P2P if url matches the specified pattern,format:reg1,reg2,reg3 -urlfilter string filter specified url fields (default \u0026quot;Signature\u0026amp;Expires\u0026amp;OSSAccessKeyId\u0026quot;) -v version -verbose verbose  Files Local Repository Directory The default local repository is ${HOME}/.small-dragonfly/dfdaemon/data/. You can change it by setting the option -localrep.\n"
},
{
	"uri": "https://d7y.io/user_guide/install_client/",
	"title": "Installing Client",
	"tags": [],
	"description": "",
	"content": "You have two options when installing the Dragonfly client: installing from the latest package, or installing from the source code. Installing from the Latest Package You can install from the latest packages we provided.\n Download a package of the client.\ncd $HOME # Replace ${package} with a package appropriate for your operating system and location wget ${package}  Available packages:\n If you\u0026rsquo;re in China:\n Linux 64-bit: http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_linux_amd64.tar.gz\n MacOS 64-bit: http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_darwin_amd64.tar.gz\n  If you\u0026rsquo;re not in China:\n Linux 64-bit: https://github.com/alibaba/Dragonfly/releases/download/v0.2.0/df-client_0.2.0_linux_amd64.tar.gz\n MacOS 64-bit: https://github.com/alibaba/Dragonfly/releases/download/v0.2.0/df-client_0.2.0_darwin_amd64.tar.gz\n   Unzip the package.\n# Replace `xxx` with the installation directory. tar -zxf df-client_0.2.0_linux_amd64.tar.gz -C xxx  Add the directory of df-client to your PATH environment variable to make sure you can directly use dfget and dfdaemon command.\n# Replace `xxx` with the installation directory. # Execute or add this line to ~/.bashrc export PATH=$PATH:xxx/df-client/   Installing from the Source Code You can also install from the source code.\nNote: You must have installed Go 1.7+, and added the Go command to the PATH environment variable.\nInstalling in $HOME/.dragonfly  Obtain the source code of Dragonfly.\ngit clone https://github.com/alibaba/Dragonfly.git  Enter the target directory.\ncd Dragonfly  Install dfdaemon and dfget in $HOME/.dragonfly/df-client.\n./build/build.sh client  Add the directory of df-client to your PATH environment variable to make sure you can directly use dfget and dfdaemon command.\n# Execute or add this line to ~/.bashrc export PATH=$HOME/.dragonfly/df-client:$PATH   Installing in Another Directory  Obtain the source code of Dragonfly.\ngit clone https://github.com/alibaba/Dragonfly.git  Enter the target directory.\ncd Dragonfly/build/client  Install the client.\n./configure --prefix=${your_installation_directory} make \u0026amp;\u0026amp; make install  Add the directory of df-client to your PATH environment variable to make sure you can directly use dfget and dfdaemon command.\n# Execute or add this line to ~/.bashrc export PATH=${your_install_directory}/df-client:$PATH   After this Task Test if the downloading works.\n```sh dfget --url \u0026quot;http://${resourceUrl}\u0026quot; --output ./resource.png --node \u0026quot;127.0.0.1\u0026quot; ``` "
},
{
	"uri": "https://d7y.io/overview/terminology/",
	"title": "Terminology",
	"tags": [],
	"description": "",
	"content": "This topic lists the common terms used throughout Dragonfly. Supernode Supernode is a long-time process with two primary responsibilities:\n It\u0026rsquo;s the tracker and scheduler in the P2P network that choose appropriate downloading net-path for each peer. It\u0026rsquo;s also a CDN server that caches downloaded data from source to avoid downloading same files repeatedly.  dfget Dfget is the client of Dragonfly used for downloading files. It\u0026rsquo;s similar to wget.\nAt the same time, it also plays the role of peer, which can transfer data between each other in P2P network.\ndfdaemon Dfdaemon is used for pulling images only. It establishes a proxy between dockerd/pouchd and registry.\nDfdaemon filters out layer fetching requests from all requests sent by dockerd/pouchd when pulling images, then uses dfget to downloading these layers.\n"
},
{
	"uri": "https://d7y.io/cli_reference/dfget/",
	"title": "dfget",
	"tags": [],
	"description": "",
	"content": "dfget is the client of Dragonfly. You can use the dfget command in the command line tool. Name dfget - the client of Dragonfly, a non-interactive P2P downloader.\nSynopsis dfget -u [URL] [options]...\nOptions  -h, --help show this help message and exit --url URL, -u URL will download a file from this url --output OUTPUT, -O OUTPUT, -o OUTPUT output path that not only contains the dir part but also name part --md5 MD5, -m MD5 expected file md5 --callsystem CALLSYSTEM system name that executes dfget,its format is company_department_appName --notbs not back source when p2p fail --locallimit LOCALLIMIT, -s LOCALLIMIT rate limit about a single download task,its format is 20M/m/K/k --totallimit TOTALLIMIT rate limit about the whole host,its format is 20M/m/K/k --identifier IDENTIFIER, -i IDENTIFIER identify download task,it is available merely when md5 param not exist --timeout TIMEOUT, --exceed TIMEOUT, -e TIMEOUT download timeout(second) --filter FILTER, -f FILTER filter some query params of url ,e.g. -f 'key\u0026amp;sign' will filter key and sign query param.in this way,different urls correspond one same download task that can use p2p mode --showbar, -b show progress bar --pattern {p2p,cdn}, -p {p2p,cdn} download pattern,cdn pattern not support totallimit --version, -v version --node NODE, -n NODE specify nodes --console show log on console --header HEADER http header, e.g. --header=\u0026quot;Accept: *\u0026quot; --header=\u0026quot;Host: abc\u0026quot; --dfdaemon caller is from df-daemon  Files /etc/dragonfly.conf This is the default configuration file for dfget, which specifies the address of the supernode.\n[node] address=127.0.0.1,127.0.0.2  ${HOME}/.small-dragonfly This directory is created by dfget when you start it for the first time.\n.small-dragonfly/ ├── data/ # stores temporary data downloaded by dfget ├── dfdaemon/ │ └── data/ # default, stores temporary data generated by dfdaemon ├── logs/ │ ├── dfclient.log # dfget's log file │ ├── dfserver.log # log file of peer server launched by dfget │ └── dfdaemon.log # dfdaemon's log file └── meta/ └── host.meta # stores meta information: peer server port "
},
{
	"uri": "https://d7y.io/user_guide/download_files/",
	"title": "Downloading Files",
	"tags": [],
	"description": "",
	"content": "Things are done differently when you download container images and download general files with Dragonfly. Prerequisites  You are using Linux operating system. You have installed Python 2.7+, and added the Python directory to the PATH environment variable. The supernode service is started.\nTip: For more information on the dfget command, see dfget. For more information on the installation of supernodes, see Installing Server.\n  Downloading container images  Specify the supernodes.\na. Open the Dragonfly configuration file.\nvi /etc/dragonfly.conf  b. Add the IP of supernodes separated by comma to the configuration file.\n[node] address=nodeIp1,nodeIp2  Start the dfget proxy (dfdaemon).\n# Start dfdaemon and specify the image repo URL. The default port is `65001`. dfdaemon --registry https://xxx.xx.x # Review dfdaemon logs tailf ~/.small-dragonfly/logs/dfdaemon.log  Tip: To list all available parameters for dfdaemon, run dfdeaemon -h.\n Configure the Daemon Mirror.\na. Modify the configuration file /etc/docker/daemon.json.\nvi /etc/docker/daemon.json  Tip: For more information on /etc/docker/daemon.json, see Docker documentation.\nb. Add or update the configuration item registry-mirrors in the configuration file.\n\u0026quot;registry-mirrors\u0026quot;: [\u0026quot;http://127.0.0.1:65001\u0026quot;]  c. Restart Docker daemon.\nsystemctl restart docker  Download an image with Dragonfly.\ndocker pull {imageName}  Note: Don\u0026rsquo;t include the image repo URL in {imageName}, because the repo URL has been specified with the registry parameter when starting dfdaemon.\n  Downloading General Files  Specify the supernodes in one of the following ways.\n Specifying with the configuration file.\n# Open the Dragonfly configuration file. vi /etc/dragonfly.conf # Add the IP of supernodes separated by comma to the configuration file [node] address=nodeIp1,nodeIp2  Specifying with the parameter in the command line.\ndfget -u \u0026quot;http://www.taobao.com\u0026quot; -o /tmp/test.html --node nodeIp1,nodeIp2  Note: When using this method, you must add the node parameter every time when you run the dfget command. And the parameter in the command line takes precedence over the configuration file.\n  Download general files with Dragonfly in one of the following ways.\n Download files with the default /etc/dragonfly.conf configuration.\ndfget --url \u0026quot;http://xxx.xx.x\u0026quot;  Tip: To list all available parameters for dfget, run dfget -h.\n Download files with your specified supernodes.\ndfget --url \u0026quot;http://xxx.xx.x\u0026quot; --node \u0026quot;127.0.0.1\u0026quot;  Download files to your specified output file.\ndfget --url \u0026quot;http://xxx.xx.x\u0026quot; -o a.txt    After this Task To review the downloading log, run less ~/.small-dragonfly/logs/dfclient.log.\n"
},
{
	"uri": "https://d7y.io/overview/",
	"title": "Overview",
	"tags": [],
	"description": "",
	"content": "Get to know Dragonfly and the common terminologies.\n What Is Dragonfly?  Dragonfly is an intelligent P2P-based image and file distribution tool. It aims to improve the efficiency and success rate of file transferring, and maximize the usage of network bandwidth, especially for the distribution of larget amounts of data, such as application distribution, cache distribution, log distribution, and image distribution.  Terminology  This topic lists the common terms used throughout Dragonfly.  "
},
{
	"uri": "https://d7y.io/user_guide/supernode_configuration/",
	"title": "Supernode Configuration",
	"tags": [],
	"description": "",
	"content": "The supernode is written in Java based on Spring Boot. You can easily set properties with command line parameters or with the configuration file. Supernode Properties Simple Property    Property Name Default Value Description     supernode.baseHome /home/admin/supernode Working directory of the supernode   supernode.systemNeedRate 20 Network rate reserved for the system (Unit: MB/s)   supernode.totalLimit 200 Network rate reserved for the supernode (Unit: MB/s)   supernode.schedulerCorePoolSize 10 Core pool size of ScheduledExecutorService   supernode.dfgetPath /usr/local/bin/dfget/ The dfget path    Cluster Property supernode.cluster This is an array property, and every member of it has these attributes:\n   Name Default Value Description     ip None The ip of the cluster member.   registerPort 8001 The register port of the cluster member.   downloadPort 8002 The download port of the cluster member.     Config it in .properties file, for example:\nsupernode.cluster[0].ip = '192.168.0.1' supernode.cluster[0].registerPort = 8001 supernode.cluster[1].ip = '192.168.0.2'  Config it in .yaml file, for example:\nsupernode: cluster: - ip: '192.168.0.1' registerPort: 8001 - ip: '192.168.0.2'   Setting Properties You have two options when setting properties of a supernode.\n Setting properties with command line parameters.\njava -D\u0026lt;propertyName\u0026gt;=\u0026lt;propertyValue\u0026gt; -jar supernode.jar  Setting properties with the configuration file.\njava -Dspring.config.location=./config.properties,\u0026lt;otherConfigFilePath\u0026gt; -jar supernode.jar  "
},
{
	"uri": "https://d7y.io/quick_start/",
	"title": "Quick Start",
	"tags": [],
	"description": "",
	"content": "Simply by starting a supernode in your Docker container, and installing the Dragonfly client, you can start downloading with Dragonfly. Prerequisites You have started your Docker container.\nStarting a Supernode in Your Docker Container  Pull the docker image we provided.\n# Replace ${imageName} with the real image name docker pull ${imageName}  Note: Choose one of the images we provide according to your geo-location, and replace ${imageName} with it:\n China: registry.cn-hangzhou.aliyuncs.com/alidragonfly/supernode:0.2.0 US: registry.us-west-1.aliyuncs.com/alidragonfly/supernode:0.2.0  Start a supernode.\n# Replace ${imageName} with the real image name docker run -d -p 8001:8001 -p 8002:8002 ${imageName}   For example, if you\u0026rsquo;re in China, run the following commands:\ndocker pull registry.cn-hangzhou.aliyuncs.com/alidragonfly/supernode:0.2.0 docker run -d -p 8001:8001 -p 8002:8002 registry.cn-hangzhou.aliyuncs.com/alidragonfly/supernode:0.2.0  Installing Dragonfly Client  Download a package of the client.\ncd $HOME # Replace ${package} with a package appropriate for your operating system and location wget ${package}  Note: Choose one of the packages we provide according to your geo-location, and replace ${package} with it:\n If you\u0026rsquo;re in China:\n Linux 64-bit: http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_linux_amd64.tar.gz\n MacOS 64-bit: http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_darwin_amd64.tar.gz\n  If you\u0026rsquo;re not in China:\n Linux 64-bit: https://github.com/alibaba/Dragonfly/releases/download/v0.2.0/df-client_0.2.0_linux_amd64.tar.gz\n MacOS 64-bit: https://github.com/alibaba/Dragonfly/releases/download/v0.2.0/df-client_0.2.0_darwin_amd64.tar.gz\n   Unzip the package.\ntar -zxf df-client_0.2.0_linux_amd64.tar.gz  Add the directory of df-client to your PATH environment variable to make sure you can directly use dfget and dfdaemon command.\n# Execute or add this line to ~/.bashrc export PATH=$PATH:$HOME/df-client/   For example, if you\u0026rsquo;re in China and using Linux, run the following commands:\ncd $HOME wget http://dragonfly-os.oss-cn-beijing.aliyuncs.com/df-client_0.2.0_linux_amd64.tar.gz tar -zxf df-client_0.2.0_linux_amd64.tar.gz # execute or add this line to ~/.bashrc export PATH=$PATH:$HOME/df-client/  Downloading a File with Dragonfly Once you have installed the Dragonfly client, you can use the dfget command to download a file.\ndfget -u 'https://github.com/alibaba/Dragonfly/blob/master/docs/images/logo.png' -o /tmp/logo.png  Tip: For more information on the dfget command, see dfget.\nPulling an Image with Dragonfly  Start dfdaemon with a specified registry, such as https://index.docker.io.\nnohup dfdaemon --registry https://index.docker.io \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp;  Add the following line to the dockerd configuration file /etc/docker/daemon.json.\n\u0026quot;registry-mirrors\u0026quot;: [\u0026quot;http://127.0.0.1:65001\u0026quot;]  Restart dockerd.\nsystemctl restart docker  Download an image with Dragonfly.\ndocker pull nginx:latest   Related Topics  Installing Server Installing Client Downloading Files supernode Configuration dfget "
},
{
	"uri": "https://d7y.io/user_guide/",
	"title": "User Guide",
	"tags": [],
	"description": "",
	"content": "Understand how to use Dragonfly from installing the server and client to downloading files.\n Installing Server  This topic explains how to install the Dragonfly server.  Installing Client  You have two options when installing the Dragonfly client: installing from the latest package, or installing from the source code.  Downloading Files  Things are done differently when you download container images and download general files with Dragonfly.  Supernode Configuration  The supernode is written in Java based on Spring Boot. You can easily set properties with command line parameters or with the configuration file.  "
},
{
	"uri": "https://d7y.io/cli_reference/",
	"title": "CLI Reference",
	"tags": [],
	"description": "",
	"content": "Understand the details of CLI commands.\n dfdaemon  dfdaemon is a proxy between pouchd/dockerd and registry used for pulling images. You can use the dfdaemon command in the command line tool.  dfget  dfget is the client of Dragonfly. You can use the dfget command in the command line tool.  "
},
{
	"uri": "https://d7y.io/api_reference/",
	"title": "APIs Provided by Supernode",
	"tags": [],
	"description": "",
	"content": "This topic explains how to use the APIs provided by the supernode (the cluster manager). Registration POST /peer/registry  Parameters Parameters are encodeds as application/x-www-form-urlencoded.\n   Parameter Type Description     cid String The client ID.   ip String (IPv4) The client IP address.   hostName String The hostname of the client.   superNodeIp String (IPv4) The IP address of the registered supernode.   port Integer The port which the client opens for P2P downloading.   callSystem String The caller identifier.   version String The client version.   dfdaemon Boolean Tells whether it is a call from dfdaemon.   path String The service path which the client offers.   rawUrl String The resource URL provided by command line parameter.   taskUrl String The resource URL.   md5 String The MD5 checksum for the resource. Optional.   identifier String The resource identifer.   headers Map Extra HTTP headers to be sent to the raw URL.    Upon receiving a request of registration from the client, the supernode constructs a new instance of based on the information provided by parameters. Specifically, it generates a task with taskId based on rawUrl, md5, and identifier.\nThen the task is stored in the memory cache. Meanwhile, the supernode retrieves extra information such as the content-length which normally would be set. The pieceSize is calculated as per the following strategy:\n If the total size is less than 200MB, then the piece size is 4MB by default. Otherwise, it equals to the smaller value between (${totalSize} / 100MB) + 2 MB and 15MB.  Next, the peer information along with the task will be recorded:\n The peerwill be saved. The taskwill be saved.  The last step is to trigger a progress.\nResponse An example response:\n{ \u0026quot;code\u0026quot;: 200, \u0026quot;data\u0026quot;: { \u0026quot;fileLength\u0026quot;: 687481, \u0026quot;pieceSize\u0026quot;: 4194304, \u0026quot;taskId\u0026quot;: \u0026quot;ba270626349198840d0255de8358b6c93fe6d57d922d036fbf40bcf3499f44a8\u0026quot; } }  Other possible values of code in the response include:\n 606: The task ID already exists. 607: The URL is invalid. 608 or 609: Authentication required.  Get Task GET /peer/task  Parameters    Parameter Type Description     superNode String (IPv4) The IP address of the super node.   dstCID String The destination client ID.   range String Byte range.   status Integer    result Integer    taskId String The task ID.   srcCID String The source client ID.    First, the supernode will analyze the status and result.\n Running: if status == 701. Success: if status == 702 and result == 501. Fail: if status == 702 and result == 500. Wait: if status == 700.  In Wait status, the supernode will save the status to be Running.\nIn Running status, the supernode will extract the piece status:\n Success: if result == 501. Fail: if result == 500. SemiSuc: if result == 503.  Tip: result == 502 suggests invalid code.\nThen the supernode updates the progress for this specific task, and checks the status of the task and the peers. After this, the supernode tells the client which peer has enough details to download another piece. Otherwise, it fails.\nResponse An example resonse:\n{ \u0026quot;code\u0026quot;: 602, \u0026quot;msg\u0026quot;: \u0026quot;client sucCount:0,cdn status:Running,cdn sucCount: 0\u0026quot; }  This example response means that the client has to wait, since no peer can serve this piece now. If there is a peer which can serve this request, the response will be something like:\n{ \u0026quot;code\u0026quot;: 601, \u0026quot;data\u0026quot;: [ { \u0026quot;cid\u0026quot;: \u0026quot;cdnnode:10.148.177.242~ba270626349198840d0255de8358b6c93fe6d57d922d036fbf40bcf3499f44a8\u0026quot;, \u0026quot;downLink\u0026quot;: \u0026quot;20480\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;/qtdown/ba2/ba270626349198840d0255de8358b6c93fe6d57d922d036fbf40bcf3499f44a8\u0026quot;, \u0026quot;peerIp\u0026quot;: \u0026quot;10.148.177.242\u0026quot;, \u0026quot;peerPort\u0026quot;: 8001, \u0026quot;pieceMd5\u0026quot;: \u0026quot;d78ef0af9e95e880fa583b41cf5ad791:687486\u0026quot;, \u0026quot;pieceNum\u0026quot;: 0, \u0026quot;pieceSize\u0026quot;: 4194304, \u0026quot;range\u0026quot;: \u0026quot;0-4194303\u0026quot; } ] }  Peer Progress GET /peer/piece/suc  Parameters    Parameter Type Description     dstCID String The destination client ID.   pieceRange String Byte range.   taskId String The task ID.   cID String The client ID.    Response An example response:\n{ \u0026quot;code\u0026quot;: 200, \u0026quot;msg\u0026quot;: \u0026quot;success\u0026quot; } "
},
{
	"uri": "https://d7y.io/faq/",
	"title": "FAQ",
	"tags": [],
	"description": "",
	"content": "Find the answers to the frequently asked questions. How can I pull images with Dragonfly? See Pulling an Image with Dragonfly.\nHow can I download files with Dragonfly? See Downloading a File with Dragonfly.\nWhat is a supernode? A supernode is a long-time process that plays the following roles:\n A tracker and scheduler in the P2P network that chooses appropriate downloading net-path for each peer. A CDN server that caches downloaded data from source to avoid downloading same files repeatedly.  What is dfget? Dfget is the Dragonfly client used for downloading files. It\u0026rsquo;s similar to wget.\nMeanwhile, it also plays the role of a peer, which can transfer data between each other in the P2P network.\nWhat is dfdaemon? Dfdaemon is only used for pulling images. It establishes a proxy between dockerd/pouchd and registry.\nDfdaemon filters out layer fetching requests from all requests sent by dockerd/pouchd when pulling images, then uses dfget to download these layers.\nWhere is the installation directory of Dragonfly client dfget? Normally, there are two installation directories:\n Dragonfly plugin for StarAgent: /home/staragent/plugins/dragonfly/dfget StarAgent\u0026rsquo;s built-in dfget: /home/staragent/bin/dfget  The Dragonfly plugin is used by default. If the Dragonfly plugin is not installed, then the StarAgent\u0026rsquo;s build-in dfget is used.\nWhere is the log directory of Dragonfly client dfget? The log directory is $HOME/.small-dragonfly/logs/dfclient.log.\nWhere is the data directory of Dragonfly client dfget? The data directory is $HOME/.small-dragonfly/data.\nEach account has its own data directory. A P2P downloading job generates two data files under this directory:\n A temporary downloading file for the target file, with the name targetFileName-sign. This file is moved to the target directory after the download is complete. A copy of the temporary downloading file for uploading, with the name targetFileName-sign.service. If no downloading jobs are downloading this file from this node, then it gets cleaned after three minutes. Before the process is completed normally, any file lasting longer than 60 minutes will be purged.  Where is the meta directory of Dragonfly client dfget? The meta directory is $HOME/.small-dragonfly/meta.\nThis directory caches the address list of the local node (IP, hostname, IDC, security domain, and so on), managing nodes, and supernodes.\nWhen started for the first time, the Dragonfly client will access the managing node. The managing node will retrieve the security domains, IDC, geo-location, and more information of this node by querying armory, and assign the most suitable supernode. The managing node also distributes the address lists of all other supernodes. dfget stores the above information in the meta directory on the local drive. When the next job is started, dfget reads the meta information from this directory, avoiding accessing the managing node repeatedly.\ndfget always finds the most suitable assigned node to register. If fails, it requests other supernodes in order. If all fail, then it requests the managing node once again, updates the meta information, and repeats the above steps. If still fails, then the job fails.\nTip: If the dfclient.log suggests that the supernode registration fails all the time, try delete all files from the meta directory and try again.\nHow to check the version of Dragonfly client dfget? If you have installed the Dragonfly client, run this command:\ndfget -v  Why is the dfget process still there after the download is complete? Because Dragonfly adopts a P2P downloading approach, dfget provides uploading services in addition to downloading services. If there are no new jobs within five minutes, the dfget process will be terminated automatically.\nHow to clean up the data directory of Dragonfly? Normally, Dragonfly automatically cleans up files which are not accessed in three minutes from the uploading file list, and the residual files that live longer than one hour from the data directory.\nFollow these steps to clean up the data directory manually:\n Identify the account to which the residual files belong. Check if there is any running dfget process started by other accounts. If there is such a process, then terminate the process, and start a dfget process with the account identified at Step 1. This process will automatically clean up the residual files from the data directory. "
},
{
	"uri": "https://d7y.io/apis/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Drgonfly SuperNode API \nOverview API is an HTTP API served by Dragonfly\u0026rsquo;s SuperNode. It is the API dfget or Harbor uses to communicate with the supernode.\nVersion information Version : 0.1\nURI scheme BasePath : /v1.24\nSchemes : HTTP, HTTPS\nTags  Peer : Create and manage peer nodes in peer networks. Piece : create and manage image/file pieces in supernode. PreheatTask : Create and manage image or file preheat task in supernode. Task : create and manage image/file distribution task in supernode.  Consumes  application/json text/plain  Produces  application/json text/plain  \nPaths \nPing GET /_ping  Description This is a dummy endpoint you can use to test if the server is accessible.\nResponses    HTTP Code Description Schema     200 no error string   500 An unexpected server error occurred. Error    Example HTTP response Response 200 json : \u0026quot;OK\u0026quot;  \nregister dfget in Supernode as a peer node POST /peers  Description dfget sends request to register in Supernode as a peer node\nParameters    Type Name Description Schema     Body body optional request body which contains peer registrar information. PeerCreateRequest    Responses    HTTP Code Description Schema     201 no error PeerCreateResponse   400 bad parameter Error   500 An unexpected server error occurred. Error    \nget a peer in supernode GET /peers/{id}  Description return low-level information of a peer in supernode.\nParameters    Type Name Description Schema     Path id required ID of peer string    Responses    HTTP Code Description Schema     200 no error PeerInfo   404 An unexpected 404 error occurred. Error   500 An unexpected server error occurred. Error    Produces  application/json  \ndelete a peer in supernode DELETE /peers/{id}  Description dfget stops playing a role as a peer in peer network constructed by supernode. when dfget lasts in five minutes without downloading or uploading task, dfget automatically sends a DELETE /peers/{id} request.\nParameters    Type Name Description Schema     Path id required ID of peer string    Responses    HTTP Code Description Schema     204 no error No Content   404 no such peer 4ErrorResponse   500 An unexpected server error occurred. Error    \nGet a piece GET /pieces/{id}  Description Get detailed information of a piece in supernode.\nParameters    Type Name Description Schema     Path id required ID of piece string    Responses    HTTP Code Description Schema     200 no error \u0026lt; PieceInfo \u0026gt; array   404 no such task 4ErrorResponse   500 An unexpected server error occurred. Error    Produces  application/json  \nUpdate a piece PUT /pieces/{id}  Description Update some information of piece, like status of piece.\nParameters    Type Name Description Schema     Path id required ID of piece string   Body PieceUpdateRequest optional request body which contains task update information PieceUpdateRequest    Responses    HTTP Code Description Schema     200 no error No Content   404 An unexpected 404 error occurred. Error   500 An unexpected server error occurred. Error    Consumes  application/json  Produces  application/json  \nCreate a Preheat Task POST /preheats  Description Create a preheat task in supernode to first download image/file which is ready. Preheat action will shorten the period for dfget to get what it wants. In details, after preheat action finishes downloading image/file to supernode, dfget can send request to setup a peer-to-peer network immediately.\nParameters    Type Name Description Schema     Body PreheatCreateRequest optional request body which contains preheat task creation information PreheatCreateRequest    Responses    HTTP Code Description Schema     200 no error PreheatCreateResponse   400 bad parameter Error   500 An unexpected server error occurred. Error    \nList Preheat Tasks GET /preheats  Description List preheat tasks in supernode of Dragonfly. This API can list all the existing preheat tasks in supernode. Note, when a preheat is finished after PreheatGCThreshold, it will be GCed, then this preheat will not be gotten by preheat tasks list API.\nResponses    HTTP Code Description Schema     200 no error \u0026lt; PreheatInfo \u0026gt; array   400 bad parameter Error   500 An unexpected server error occurred. Error    \nGet a preheat task GET /preheats/{id}  Description get detailed information of a preheat task in supernode.\nParameters    Type Name Description Schema     Path id required ID of preheat task string    Responses    HTTP Code Description Schema     200 no error PreheatInfo   404 no such preheat task 4ErrorResponse   500 An unexpected server error occurred. Error    Produces  application/json  \ncreate a task POST /tasks  Description Create a peer-to-peer downloading task in supernode.\nParameters    Type Name Description Schema     Body body optional request body which contains task creation information TaskCreateRequest    Responses    HTTP Code Description Schema     201 no error TaskCreateResponse   400 bad parameter Error   500 An unexpected server error occurred. Error    \nget a task GET /tasks/{id}  Description return low-level information of a task in supernode.\nParameters    Type Name Description Schema     Path id required ID of task string    Responses    HTTP Code Description Schema     200 no error TaskInfo   404 An unexpected 404 error occurred. Error   500 An unexpected server error occurred. Error    Produces  application/json  \nupdate a task PUT /tasks/{id}  Description update information of a task.\nParameters    Type Name Description Schema     Path id required ID of task string   Body TaskUpdateRequest optional request body which contains task update information\u0026rdquo; TaskUpdateRequest    Responses    HTTP Code Description Schema     200 no error No Content   404 An unexpected 404 error occurred. Error   500 An unexpected server error occurred. Error    Consumes  application/json  Produces  application/json  \ndelete a task DELETE /tasks/{id}  Description delete a peer-to-peer task in supernode.\nParameters    Type Name Description Schema     Path id required ID of task string    Responses    HTTP Code Description Schema     204 no error No Content   404 no such peer 4ErrorResponse   500 An unexpected server error occurred. Error    \nGet pieces in task GET /tasks/{id}/pieces  Description Get fixed number of pieces in a task. The number is set in query.\nParameters    Type Name Description Schema     Path id required ID of task string   Query num optional Request number of pieces of task. If request number is larger than the total pieces in supernode,\nsupernode returns the total pieces of task. If not set, supernode will set 4 by default. integer (int64)    Responses    HTTP Code Description Schema     200 no error \u0026lt; PieceInfo \u0026gt; array   404 no such task 4ErrorResponse   500 An unexpected server error occurred. Error    Produces  application/json  \nDefinitions \nError    Name Schema     message optional string    \nErrorResponse It contains a code that identify which error occurred for client processing and a detailed error message to read.\n   Name Description Schema     code optional the code of this error, it\u0026rsquo;s convenient for client to process with certain error. integer   message optional detailed error message string    \nPeerCreateRequest PeerCreateRequest is used to create a peer instance in supernode. Usually, when dfget is going to register in supernode as a peer, it will send PeerCreateRequest to supernode.\n   Name Description Schema     ID optional Peer ID of dfget client. Every peer has a unique ID among peer network. string   IP optional IP address which peer client carries string (ipv4)   callSystem optional This field is for debugging. When caller of dfget is using it to files, he can pass callSystem\nname to dfget. When this field is passing to supernode, supernode has ability to filter them via some black/white list to guarantee security, or some other purposes. Minimum length : 1 string   dfdaemon optional tells whether it is a call from dfdaemon. boolean   hostName optional host name of peer client node, as a valid RFC 1123 hostname. Minimum length : 1 string (hostname)   path optional This is actually an HTTP URLPATH of dfget. Other peers can access the source file via this PATH. string   port optional when registering, dfget will setup one uploader process. This one acts as a server for peer pulling tasks.\nThis port is which this server listens on. Minimum value : 30000 Maximum value : 65535 integer (int64)   version optional version number of dfget binary string    \nPeerCreateResponse ID of created peer.\n   Name Description Schema     ID optional ID of created peer. string    \nPeerInfo The detailed information of a peer in supernode.\n   Name Description Schema     ID optional ID of peer string   IP optional IP address which peer client carries string (ipv4)   callSystem optional This field is for debugging. When caller of dfget is using it to files, he can pass callSystem\nname to dfget. When this field is passing to supernode, supernode has ability to filter them via some black/white list to guarantee security, or some other purposes. Minimum length : 1 string   dfdaemon optional tells whether it is a call from dfdaemon. boolean   hostName optional host name of peer client node, as a valid RFC 1123 hostname. Minimum length : 1 string (hostname)   path optional This is actually an HTTP URLPATH of dfget. Other peers can access the source file via this PATH. string   port optional when registering, dfget will setup one uploader process. This one acts as a server for peer pulling tasks.\nThis port is which this server listens on. Minimum value : 30000 Maximum value : 65535 integer (int64)   version optional version number of dfget binary string    \nPieceInfo Peer\u0026rsquo;s detailed information in supernode.\n   Name Description Schema     ID optional ID of the peer string    \nPieceUpdateRequest    Name Schema     ID optional string    \nPreheatCreateRequest Request option of creating a preheat task in supernode.\n   Name Description Schema     filter optional URL may contains some changeful query parameters such as authentication parameters. Dragonfly will filter these parameter via \u0026lsquo;filter\u0026rsquo;. The usage of it is that different URL may generate the same download taskID. string   headers optional If there is any authentication step of the remote server, the headers should contains authenticated information.\nDragonfly will sent request taking the headers to remote server. \u0026lt; string, string \u0026gt; map   identifier optional This field is used for generating new downloading taskID to indetify different downloading task of remote URL. string   type optional this must be image or file string   url optional the image or file location string    \nPreheatCreateResponse Response of a preheat creation request.\n   Name Schema     ID optional string    \nPreheatInfo return detailed information of a preheat task in supernode. An image preheat task may contain multiple downloading task because that an image may have more than one layer.\n   Name Description Schema     ID optional ID of preheat task. string   finishTime optional the preheat task finish time string (date-time)   startTime optional the preheat task start time string (date-time)   status optional The status of preheat task.\nWAITING \u0026mdash;\u0026ndash;\u0026gt; RUNNING \u0026mdash;\u0026ndash;\u0026gt; SUCCESS\n|\u0026ndash;\u0026gt; FAILED\nThe initial status of a created preheat task is WAITING.\nIt\u0026rsquo;s finished when a preheat task\u0026rsquo;s status is FAILED or SUCCESS.\nA finished preheat task\u0026rsquo;s information can be queried within 24 hours. enum (WAITING, RUNNING, FAILED, SUCCESS)    \nTaskCreateRequest    Name Description Schema     headers optional extra HTTP headers sent to the rawURL.\nThis field is carried with the request to supernode. Supernode will extract these HTTP headers, and set them in HTTP downloading requests\nfrom source server as user\u0026rsquo;s wish. \u0026lt; string, string \u0026gt; map   identifier optional special attribute of remote source file. This field is used with taskURL to generate new taskID to\nindetify different downloading task of remote source file. For example, if user A and user B uses\nthe same taskURL and taskID to download file, A and B will share the same peer network to distribute files.\nIf user A additionally adds an indentifier with taskURL, while user B still carries only taskURL, then A\u0026rsquo;s\ngenerated taskID is different from B, and the result is that two users use different peer networks. string   md5 optional md5 checksum for the resource to distribute. dfget catches this parameter from dfget\u0026rsquo;s CLI\nand passes it to supernode. When supernode finishes downloading file/image from the source location,\nit will validate the source file with this md5 value to check whether this is a valid file. string   rawURL optional The is the resource\u0026rsquo;s URL which user uses dfget to download. The location of URL can be anywhere, LAN or WAN.\nFor image distribution, this is image layer\u0026rsquo;s URL in image registry.\nThe resource url is provided by command line parameter. string   taskURL optional taskURL is generated from rawURL. rawURL may contains some queries or parameter, dfget will filter some queries via\n\u0026ndash;filter parameter of dfget. The usage of it is that different rawURL may generate the same taskID. string    \nTaskCreateResponse response get from task creation request.\n   Name Description Schema     ID optional ID of the created task. string    \nTaskInfo detailed information about task in supernode.\n   Name Description Schema     ID optional ID of the task. string    \nTaskUpdateRequest request used to update task attributes.\n   Name Description Schema     ID optional ID of the created task. string    "
},
{
	"uri": "https://d7y.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://d7y.io/",
	"title": "Dragonfly",
	"tags": [],
	"description": "",
	"content": "       \nDragonfly is an intelligent P2P-based image and file distribution tool. It aims to improve the efficiency and success rate of file transferring, and maximize the usage of network bandwidth, especially for the distribution of larget amounts of data, such as application distribution, cache distribution, log distribution, and image distribution. At Alibaba, every month Dragonfly is invoked two billion times and distributes 3.4PB of data. Dragonfly has become one of the most important pieces of infrastructure at Alibaba.\nWhile container technologies makes DevOps life easier most of the time, it surely brings some challenges: for example the efficiency of image distribution, especially when you have to replicate image distribution on several hosts.\nDragonfly works extremely well with both Docker and PouchContainer in this scenario. It\u0026rsquo;s also compatible with containers of other formats. It delivers up to 57 times the throughput of native docker and saves up to 99.5% of the out bandwidth of registry.\nDragonfly makes it simple and cost-effective to set up, operate, and scale any kind of file, image, or data distribution.\nWhy Dragonfly? This project is an open-source version of the Dragonfly used at Alibaba. It has the following features:\nNote: More Alibaba-internal features will be made available to open-source users soon. Stay tuned!\n P2P-based file distribution: By using the P2P technology for file transmission, it makes the most out of the bandwidth resources of each peer to improve downloading efficiency, and saves a lot of cross-IDC bandwidth, especially the costly cross-board bandwidth. Non-invasive support to all kinds of container technologies: Dragonfly can seamlessly support various containers for distributing images. Host level speed limit: In addition to rate limit for the current download task like many other downloading tools (for example wget and curl), Dragonfly also provides rate limit for the entire host. Passive CDN: The CDN mechanism can avoid repetitive remote downloads. Strong consistency: Dragonfly can make sure that all downloaded files are consistent even if users do not provide any check code (MD5). Disk protection and highly efficient IO: Prechecking disk space, delaying synchronization, writing file blocks in the best order, isolating net-read/disk-write, and so on. High performance: Cluster Manager is completely closed-loop, which means that it doesn\u0026rsquo;t rely on any database or distributed cache, processing requests with extremely high performance. Auto-isolation of Exception: Dragonfly will automatically isolate exception nodes (peer or Cluster Manager) to improve download stability. No pressure on file source: Generally, only a few Cluster Managers will download files from the source. Support standard HTTP header: Support submitting authentication information through HTTP header. Effective concurrency control of Registry Auth: Reduce the pressure on the Registry Auth Service. Simple and easy to use: Very few configurations are needed.  How Does It Stack Up Against Traditional Solution? We carried out an experiment to compare the performance of Dragonfly and wget.\n   Test Environment      Dragonfly Server 2 * (24-Core 64GB-RAM 2000Mb/s)   File Source Server 2 * (24-Core 64GB-RAM 2000Mb/s)   Client 4-Core 8GB-RAM 200Mb/s   Target File Size 200MB   Experiment Date April 20, 2016    The expeirment result is as shown in the following figure.\nAs you can see in the chart, for Dragonfly, no matter how many clients are downloading, the average downloading time is always about 12 seconds. But for wget, the downloading time keeps increasing with the number of clients. When the number of wget clients reaches 1,200, the file source crashed and therefore cannot serve any client.\nHow Does It Work? Dragonfly works slightly differently when downloading general files and downloading container images.\nDownloading General Files The Cluster Manager is also called a supernode, which is responsible for CDN and scheduling every peer to transfer blocks between each other. dfget is the P2P client, which is also called \u0026ldquo;peer\u0026rdquo;. It\u0026rsquo;s mainly used to download and share blocks.\nDownloading Container Images Registry is similar to the file server above. dfget proxy is also called dfdaemon, which intercepts HTTP requests from docker pull or docker push, and then decides which requests to process with dfget.\nDownloading Blocks Every file is divided into multiple blocks, which are transmitted between peers. Each peer is a P2P client. Cluster Manager will check if the corresponding file exists in the local disk. If not, it will be downloaded into Cluster Manager from file server.\nWho has adopted Dragonfly? Here are some of the adoptors of project Dragonfly. If you are using Dragonfly to improve your distribution, please don\u0026rsquo;t hesitate to reach out to us and show your support.\n\u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp; \u0026nbsp;\nCommunity You are encouraged to communicate with us via GitHub issues or pull requests.\nFollow us on other platforms:\n Gitter Chat: dragonfly Twitter: @dragonfly_oss  License Dragonfly is available under the Apache 2.0 License.\n"
},
{
	"uri": "https://d7y.io/roadmap/",
	"title": "Roadmap",
	"tags": [],
	"description": "",
	"content": " CNCF Ecosystem  Deploy SuperNode using Helm in Kubernetes Deploy dfget \u0026amp; dfdaemon using DaemonSet in Kubernetes Integration with Harbor: preheat image feature  Security  Support private container image Support authentication in SuperNode API Different encryption algorithm in data transmission  Efficiency  Dynamic downloading rate limiting and scheduling algorithm Use IPFS to share block datas between SuperNodes  Openness  Plug-In policy for CNCF projects Highly user-customized modules Refactor SuperNode with Golang  Scalability  Simplify the complexity of scaling SuperNodes in Kubernetes  Stability  Cluster the SuperNode to decrease possibility of failure  "
},
{
	"uri": "https://d7y.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]